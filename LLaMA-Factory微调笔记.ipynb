{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792528bc-8a3b-49b1-ae45-b464b86244d8",
   "metadata": {},
   "source": [
    "# LLaMA-Factory微调Qwen3-4B-BASE\n",
    "\n",
    "使用AutoDL vGPU-32GB 进行实验，已预装CUDA\n",
    "\n",
    "环境为\n",
    "torch=2.3.0\n",
    "python=3.12\n",
    "ubuntu22.04\n",
    "cuda_version=12.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede95980-4b7b-4836-81a6-b5d0b2b026d8",
   "metadata": {},
   "source": [
    "## 1.安装LLaMA-Factory库及相关依赖（官方安装方法）\n",
    "```bash\n",
    "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
    "cd LLaMA-Factory\n",
    "pip install -e \".[torch,metrics]\" --no-build-isolation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99641a57-543c-452a-91c0-235034504b79",
   "metadata": {},
   "source": [
    "### 检查LLaMA-Factory安装\n",
    "\n",
    "#### 检查版本号\n",
    "```bash\n",
    "llamafactory-cli version\n",
    "```"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0f62d53-93de-4d88-bb85-b25e01bcdaa8",
   "metadata": {},
   "source": [
    "----------------------------------------------------------\n",
    "| Welcome to LLaMA Factory, version 0.9.4.dev0           |\n",
    "|                                                        |\n",
    "| Project page: https://github.com/hiyouga/LLaMA-Factory |\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad50dc-607d-402b-9cf7-32f4d8c4783b",
   "metadata": {},
   "source": [
    "### 安装bitsandtypes\n",
    "\n",
    "用于启用QLoRA\n",
    "```bash\n",
    "pip install bitsandtypes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb976899-1366-4d29-8045-3166e0e2ccc1",
   "metadata": {},
   "source": [
    "## 2.安装Qwen3模型\n",
    "\n",
    "选用modelscope魔塔社区下载（国内网站下载快）\n",
    "\n",
    "### 安装modelscope\n",
    "```bash\n",
    "pip install modelscope\n",
    "```\n",
    "### 下载Qwen3-4B-BASE 模型到指定文件夹\n",
    "\n",
    "命令行下载方式\n",
    "```bash\n",
    "modelscope download --model Qwen/Qwen3-4B-Base --local_dir /root/autodl-tmp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3743b-22df-4417-b555-575aea6583d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK下载方式\n",
    "# 模型下载\n",
    "\n",
    "from modelscope import snapshot_download\n",
    "model_dir = snapshot_download('Qwen/Qwen3-4B-Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73ac63-cc7c-4a01-93ad-56f7629dbb4d",
   "metadata": {},
   "source": [
    "### 使用transformers库测试模型是否正常推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3ada801-4b95-4c38-b6fc-340b5bf70a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099c7e222ba44849ad1d15f16a960475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': '<think>\\nOkay, the user is asking, \"Who are you?\" I need to respond appropriately. First, I should explain that I\\'m a large language model developed by Alibaba Cloud. I should mention my name, Qwen, and my purpose as an AI assistant. I should also highlight my capabilities, like answering questions, creating content, and providing assistance in various tasks. I need to make sure the response is clear and concise. Also, I should invite the user to ask questions or request help. Let me check if there\\'s any additional information that\\'s important to include. Maybe mention that I can help with multiple languages or specific tasks. Alright, that should cover it.\\n</think>\\n\\nHello! I am Qwen, a large language model developed by Alibaba Cloud. I am designed to assist with a wide range of tasks, including answering questions, creating content, and providing helpful information. I can help with everything from simple queries to more complex problem-solving. Feel free to ask me anything you need help with!'}]}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "MODEL_PATH = \"/root/autodl-tmp/Qwen3-4B\"\n",
    "pipe = pipeline(\"text-generation\", model=MODEL_PATH)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7a4e9b-1bcb-48d9-bc7a-a63c52b07b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b347b7748f24fd7b009a72f727a6ee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking, \"Who are you?\" I need to respond in a friendly and helpful manner. Let me start by introducing myself as Qwen, the large language model developed\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "MODEL_PATH = \"/root/autodl-tmp/Qwen3-4B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "\tmessages,\n",
    "\tadd_generation_prompt=True,\n",
    "\ttokenize=True,\n",
    "\treturn_dict=True,\n",
    "\treturn_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=40)\n",
    "print(tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[-1]:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b9fd98-bc83-4ae3-9fe2-26ed10ef7d03",
   "metadata": {},
   "source": [
    "## 3.准备数据\n",
    "本次微调使用医疗大模型的训练数据优化问诊场景\n",
    "### 在终端下载数据集到指定文件夹\n",
    "```bash\n",
    "modelscope download --dataset swift/medical_zh train_zh_0.jsonl --local_dir /root/LLaMA-Factory/data\n",
    "modelscope download --dataset swift/medical_zh valid_zh_0.jsonl --local_dir /root/LLaMA-Factory/data\n",
    "modelscope download --dataset swift/medical_zh test_zh_0.jsonl --local_dir /root/LLaMA-Factory/data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407e5fcc-a068-4acb-8414-a8c9b586597f",
   "metadata": {},
   "source": [
    "### 检查数据格式（终端）\n",
    "```bash\n",
    "cd /root/auto-tmp/data/medical\n",
    "head -3 train_zh_0.json\n",
    "```\n",
    "样例数据如下：\n",
    "\n",
    "{\"instruction\": \"血热的临床表现是什么?\", \"input\": \"\", \"output\": \"初发或复发病不久。皮疹发展迅速，呈点滴状、钱币状或混合状。常见丘疹、斑丘疹、大小不等的斑片，潮红、鲜红或深红色。散布于体表各处或几处，以躯干、四肢多见，亦可先从头面开始，逐渐发展至全身。新皮疹不断出现，表面覆有银白色鳞屑，干燥易脱落，剥刮后有点状出血。可有同形反应;伴瘙痒、心烦口渴。大便秘结、小便短黄，舌质红赤，苔薄黄或根部黄厚，脉弦滑或滑数。血热炽盛病机，主要表现在如下四个面：一、热象：血热多属阳盛则热之实性、热性病机和病证、并表现出热象。二、血行加速：血得热则行，可使血流加速，且使脉道扩张，络脉充血，故可见面红目赤，舌色深红（即舌绛）等症。三、动血：在血行加速与脉道扩张的基础上，血分有热，可灼伤脉络，引起出血，称为“热迫血妄行”，或称动血。四、扰乱心神：血热炽盛则扰动心神，心主血脉而藏神，血脉与心相通，故血热则使心神不安，而见心烦，或躁扰发狂等症。\"}\n",
    "{\"instruction\": \"帕金森叠加综合征的辅助治疗有些什么？\", \"input\": \"\", \"output\": \"综合治疗；康复训练；生活护理指导；低频重复经颅磁刺激治疗\"}\n",
    "{\"instruction\": \"卵巢癌肉瘤的影像学检查有些什么？\", \"input\": \"\", \"output\": \"超声漏诊；声像图；MR检查；肿物超声；术前超声；CT检查\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58f4c82-eb58-467b-8a0d-c13e04e0edd8",
   "metadata": {},
   "source": [
    "### 提取训练集的前1000条作为微调训练数据\n",
    "```bash\n",
    "head -1000 train_zh_0.jsonl > train_zh_1000.jsonl/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590ae681-9882-4a45-b46a-9e67bceac101",
   "metadata": {},
   "source": [
    "### 添加描述文件\n",
    "#### 在dataset_info.json文件中增加所用数据集描述:\n",
    "\n",
    "```json\n",
    "...\n",
    "  \"train_zh\": {\n",
    "    \"file_name\": \"train_zh_0.json\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  },\n",
    "  \"train_zh_1000\": {\n",
    "    \"file_name\": \"train_zh_1000.json\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  },\n",
    "  \"test_zh\": {\n",
    "    \"file_name\": \"test_zh_0.json\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  },\n",
    "  \"valid_zh\": {\n",
    "    \"file_name\": \"valid_zh_0.json\",\n",
    "    \"columns\": {\n",
    "      \"prompt\": \"instruction\",\n",
    "      \"query\": \"input\",\n",
    "      \"response\": \"output\"\n",
    "    }\n",
    "  }\n",
    "...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d72eb-0169-4838-8439-d1f6f87aef82",
   "metadata": {},
   "source": [
    "## 4.正式开始微调大模型！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9551ae4-2691-4dab-8555-de6111e5f9b4",
   "metadata": {},
   "source": [
    "### 打开LLaMA-Factory自带的webui界面\n",
    "```bash\n",
    "llamafactory-cli webui\n",
    "```\n",
    "此时会提示\n",
    "- To create a public link, set `share=True` in `launch()`.\n",
    "\n",
    "打开LLaMA-Factory/src/llamafactory/webui/interface.py，将两个share从gradio_share改为True\n",
    "\n",
    "并根据提示下载文件移动到指定文件夹并且授予权限后重新启动webui界面/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4f0f4-d4cb-4bc0-9072-a64b913252ba",
   "metadata": {},
   "source": [
    "根据提示选择模型与数据集，直接开始训练\n",
    "\n",
    "好不稳定！！！！webui还是太难用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63391f1b-49e2-4737-8c01-3316cc7aae9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
